---
Author:
  - Кузнецов Андрей
  - AIRI
tags:
  - мультимодальные_модели
  - конспект
  - OmniFusion
  - VLLM
  - лекция
  - RuDOLPH
date: 2024-10-28
---
# Источник

* Андрей Кузнецов | Мультимодальные модели [ссылка](https://vk.com/video-210514085_456239080)
# Конспект

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-5.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-6.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-7.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-8.png)
Для модели новый тип данных (модальность) - это просто новый язык, на котором она будет говорить.
"imglish – язык картинок".

Для модальности нужен:
* свой энкодер
* своя токенизация

В итоге мы учимся комбинировать "привычный язык" для модели (обычно текст) с новым, например, картинками.

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-9.png)
Трансформер - модель, которая на основе механизма `Attention`(Внимание) умеет давать оценку вероятности появления следующего токена(интерпретация слова для NLP, кусочка картинки для ViT).

Задаем модели `Контект`. 
> `Контекст` - некоторая кратковременная область памяти для модели, которая содержит опр. данные. Модель использует эти данные для оценки вероятности появления следующего токена.

> `Токен` - механизм интерпретации символов(текста) в числовой вид, который потом трансформируется в эмбединги (вектора признаков).

В целом все состоит из 
* encoder(кодировщика), который учится создавать эмбединги
* decoder(декодировщика), который учится предсказывать вероятность появления следующего токена

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-10.png)
Вокруг модели появляется некоторая обертка, которая позволяет трансформировать все типы данных в понятный для фундаментальной модели(LLM) вид.
Т.е. конвертировать эмбединги новых типов данных (например, от модели кодирующей признаки изображений ViT) -> в эмбединги нашей LLM.
Мы учим как бы адаптер, или мостик между моделями =) Переводчика между языками моделей.

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-11.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-12.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-13.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-14.png)
# Подходы к обучению мультимодальных моделей:

## 1. Tool augmented LLM

LLM "расширенная" возможностью вызывать
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-15.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-16.png)
LLM работает с текстом.
У нее есть набор моделей, спец моделей которым она может скормить неизвестную ей модальность и получить текстовое описание.
Мы обучаем ее обрабатывать специфические запросы пользователя.
После этого модель понимая, что пришел специфический запрос, - вызывает специальную модель для обработки этого запроса, получает от нее текст, и отвечает с использованием этого контекста.
Пример:
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-17.png)
Пользователь отправляет в сервис картинку.
Есть отправление в LLM в виде пути к картинке.
LLM решает, нужно ли ей вызвать спец модели для работы с картинками?
Если да вызывает набор спец моделей для картинок
* Image Captioning - описание изображения
* Dense Captioning - декрипторы объектов и их местоположение на изображении
* Object Tagger - описывает тегами, что находится на изображении
* Face Detector - ищет лица на изображениях
и забирает от них всех текстовый вывод и суммаризует результат.
Если спрашивают что то об игроке знаменитости, то LLM еще и может отправить запрос в поисковую систему например в Bing, получить от туда текстовые ответы и использовать их для ответа пользователю (RAG).

Работает.
### Проблемы
* Чем больше разнородных данных и задач, тем больше спец моделей и спец сценариев надо придумывать!
* Модель LLM начинает путаться когда и какую спец модель звать!
## 2. End to end Mutimodal LLM

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-18.png)

Научим модель понимать картинки естественным образом как текст!
* возьмем токенизатор, выделим в нем отдельные типы токенов в словаре, которые будут отвечать за картинку.
* и будем обучать модель понимать картинки и текст одновременно
* на перемешанном inter lift датасете, желательно еще и в диалоговом формате в котором перемешаны и картинки и текст

Декодер остается тот же самый, но словарь увеличивается токенами картинок.
И мы учим модель предсказывать не только текстовые токены, но еще и картиночные!
### Проблема
* Такая LLM учится с нуля практически, а они требуют очень больших ресурсов на обучение!

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-19.png)
Архитектура
Текст вопрос о картинке 384, картинка 24х24 пикселя, текст описывающий картинку 128.

* закрыли левый текст, получилась задача - image captioning
* закрыли правый текст, получилась задача - text2image
* закрыли картинку, получили LLM
* и т.д.

Если ничего не отключать, то на один текстовый запрос (левый текст), модель будет давать два ответа - картинкой и текстом.
И интересно что это позволяет посмотреть как думает модель.
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-20.png)
Модель ответила текстом о том кто такой Чебурашка, и сгенерировала его картинку.
Текстовый ответ на математическую задачу - правильный, а генерация похожа на обложку учебника по математике, но там не наш пример. (Как бы что то на тему).
## 3. Modality bridging with pretrained models

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-21.png)
Объединение модальностей с помощью предварительно подготовленных моделей.

Это механизм `Адаптеров`:
* есть предобученная фундаментальная модель (LLM)
* есть предобученные энкодеры на каждую модальность (например ViT - Visual Transformer'ы, сверточные модели, единый энкодер и т.д.)
т.е. некоторые модели, которые могут из картинки получить вектор признаков.
* мы обучаем модель "мостик", которая проецирует 
"эмбединги от моделей дающих модальность" -> "эмбединги в пространстве LLM"

Обучаем модель-переводчика эмбедингов с языка моделей модальности в эмбединги модели.
=)

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-22.png)
В этой модели строится адаптер, который умеет смешивать несколько энкодеров вместе!
Фиолетовый блок - `Feature Merging`.

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-23.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-24.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-25.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-26.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-27.png)
#### Модель OmniFusion:
* AIRI-Institute/OmniFusion [ссылка](https://github.com/AIRI-Institute/omnifusion)
* OmniFusion: выходим за границы текста / Хабр [ссылка](https://habr.com/ru/companies/airi/articles/775108/)

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-28.png)
Как видно из графика, VLLM имеют тот же ранг точности, что и LLM, на которых они основаны.
Вклад фундаментальной модели(LLM) чрезвычайно важен! От нее зависит очень много.

Но с некоторыми задачами понимания модели не справляются, пример с распознаванием "5-ки". Почти все модели отвечают, что то непонятное.
Или сколько раз пересекаются однопиксельные линий между собой?
Visual encoder будет сжимать картинку и в сжатом представлении эти линии растворяться. Поэтому модель не сможет ответить на этот вопрос.

![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-29.png)
Есть специальные архитектуры для работы с видео, которые с помощью Motion Tokenizer, которые обеспечивают связность информации между кадрами видео.
Он обеспечивает кодировку используя разницу между кадрами. Вся информация нам не нужна.

Можно использовать подобные модели для генерации видео.
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-30.png)
![](../files/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом-20241029-31.png)
