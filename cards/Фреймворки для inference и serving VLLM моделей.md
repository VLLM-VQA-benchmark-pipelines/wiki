---
Author:
  - Ширяев Антон
  - Изюмова Анастасия
  - Овчинникова Юлия
tags:
  - vLLM
  - Hugging_Face
  - SGLang
  - VLLM
  - inference
  - serving
date: 2024-11-10
---
## Фреймворки
### Hugging Face

1. Позволяет создать датасет	    
2. Позволяет опубликовать свой датасет	    
3. Инструменты для оценивания моделей на датасет.	    
4. Умеет считать метрики WER и CER

### vLLM

Фреймворк для оптимизированного инференса и сервинга моделей    

Полезные ссылки о vllm ([ссылка](https://habr.com/ru/companies/mts_ai/articles/791594/) ускорение в 20 раз, сравнение инструментов сервинга LLM [ссылка](https://vc.ru/ai/1247008-sravnenie-proizvoditelnosti-servinga-llama-3-na-vllm-lmdeploy-mlc-llm-tensorrt-llm-i-tgi?ysclid=m3fjcweeog473826955)).
Как будто TensorRT + Triton inference server сразу) При этом поддерживаются не только nvidia GPU.
Из объективного анализа фреймворков для сервинга привлекательнее всего выглядит именно vllm =)

### SGLang

[Ссылка](https://github.com/sgl-project/sglang) (2024)

SGLang — фреймворк для работы с LLM и VLM с открытым исходным кодом. 
Основные функции включают:
 - Ускоренный бэкэнд: 
	 - кэширования префиксов (RadixAttention)
	 - декодирование с ограничением перехода вперед 
	 - непрерывное пакетирование
	 - token attention (paged attention), 
	 - тензорный параллелизм
	 - ядра FlashInfer
	 - chunked prefill
	 - квантование (INT4/FP8/AWQ/GPTQ)
- Интерфейс:
		- вызовы с цепочкой генерации
		- продвинутый промптинг
		- контроль потока
		- многомодальные входы
		- параллелизм
		- внешние взаимодействия
- Расширенная поддержка моделей: 
	- генеративные модели (Llama, Gemma, Mistral, QWen, DeepSeek, LLaVA и т. д.), 
	- встраиваемые модели (e5-mistral, gte, mcdse)
	- модели вознаграждения (Skywork)
	- можно добавлять свои модели