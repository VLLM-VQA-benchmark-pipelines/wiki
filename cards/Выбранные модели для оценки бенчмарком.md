---
Author:
  - Ширяев Антон
  - Изюмова Анастасия
  - Овчинникова Юлия
  - Лукин Семен
  - Капустин Евгений
tags:
  - VLLM
  - модели
  - бенчмарк
date: 2024-11-23
---
Наша команда:
* произвела обзор самых последних моделей для решения задачи VQA
* презентовала свои находки стейкхолдерам
* согласовала со стейкхолдерами список наиболее перспективных моделей для бенчмарка
# Список моделей для бенчмарка:

## 1. Qwen2-VL

 Модели `Qwen2-VL-2B` и `Qwen2-VL-7B` показывают хорошие результаты ([ссылка](https://gitlab.com/document_vqa/qwen2-vl#результаты-тестов-модели-qwen2-vl-2b-instruct)).
### Материалы

#### от разработчиков
* [ссылка на статью](https://arxiv.org/pdf/2409.12191)
* [ссылка на блог](https://qwenlm.github.io/blog/qwen2-vl/)
* [ссылка на HuggingFace](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct)
* [ссылка на GitHub](https://github.com/QwenLM/Qwen2-VL) 
* [ссылка на Docker image](https://github.com/QwenLM/Qwen2-VL?tab=readme-ov-file#-docker) [ссылка на Dockerfile-cu121](https://github.com/QwenLM/Qwen2-VL/blob/main/docker/Dockerfile-cu121)

#### от Антона Ширяева
* репозиторий с запуском и тестами модели [ссылка](https://gitlab.com/document_vqa/qwen2-vl)
* код для ответов на вопросы моделью по документам [ссылка](https://gitlab.com/document_vqa/qwen2-vl/-/blob/main/src/run_predict.py?ref_type=heads)
* [ссылка на Dockerfile-cu124](https://github.com/QwenLM/Qwen2-VL/blob/main/docker/Dockerfile-cu121) [инструкции по сборке и запуску контейнера](https://gitlab.com/document_vqa/qwen2-vl#docker-контейнер)

#### от Анастасии Изюмовой:
* Jupyter Notebook с запуском модели на фреймворке vLLM [ссылка](../../../files/vlm.ipynb)

#### от канала MachineLearning в Telegram
Туториал по файнтюну Qwen2-VL-7B с использованием экосистемы Hugging Face [ссылка](Туториал%20по%20файнтюну%20Qwen2-VL-7B%20с%20использованием%20экосистемы%20Hugging%20Face.md)

## 2. MiniCPM-V 2.6

Имеет более продвинутый `Vision encoder` по сравнению с `Qwen2-VL`.
Лицензия на модель не свободная.
### Материалы
#### от разработчиков
* модель [ссылка](https://huggingface.co/openbmb/MiniCPM-V-2_6) 
#### от Антона Ширяева
* репозиторий с запуском и тестами модели [ссылка](https://gitlab.com/document_vqa/minicpm-v-2-6)
#### от Анастасии Изюмовой
* Jupyter Notebook с запуском модели на фреймворке vLLM [ссылка](../../../files/vlm.ipynb)
## 3. RuDOLPH

Материалы:
* [ссылка на конспект](../../../cards/Конспект%20Андрей%20Кузнецов%20Мультимодальные%20модели,%20как%20научить%20языковые%20модели%20работать%20не%20только%20с%20текстом.md)
## 4. LayoutLM2, 3, XML
## 5. deepvk/llava-saiga-8b
## 6. Griffon-G
* перспективная модель по научной статье.
* поддерживает только английский язык =( 
* свободная лицензия `Apache-2.0`

Надо будет пропты и примеры от него попробовать с нашими VLLM )
Интересно могут ли они так же как и он?
### Материалы
#### от разработчиков
* [ссылка](https://paperswithcode.com/paper/griffon-g-bridging-vision-language-and-vision)
* [ссылка на github](https://github.com/jefferyzhan/griffon) 