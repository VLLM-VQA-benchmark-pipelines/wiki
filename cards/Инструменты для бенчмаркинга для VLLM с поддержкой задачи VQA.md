---
Author:
  - Ширяев Антон
tags:
  - tools
date:
---

## Задачи

Запуск бенчмарка:
- Запустить бенчмарк с парой датасетов на которых он умеет работать какой то из моделей которые он поддерживает.    
- Запустить маленьком кусочке датасета (из 20 картинок и вопросов по ним)    

Поиск подходящего формата датасета:
- Посмотрим готовые бенчмарки    
- Посмотреть форматы датасетов которые они поддерживает    
- Поискать среди этих форматов наиболее подходящие под нашу задачу    
- Если такой формат найден то используем его!    

Поиск способа добавления нашего формата датасета:
- Если не найден, то делаем свой кастомный.    
- Надо понять какой класс написать для того, чтобы этот бенчмарк смог работать с датасетом нашего формата.    

Какие метрики поддерживает данный бенчмарк?
- Посмотреть какие метрики поддерживаются    
- Есть ли полезные для наших задач    

Запуск наших моделей на бенчмарке:
- Смотрим какие поддерживаются и тестируем их на мини кусочках датасета(убеждаемся что все работает)    
- Ищем способ как добавить свою новую модель в данный бенчмарк. Есть какой то класс, описывающий предикт моделью на картинке при заданном вопросе. 
- Реализуем свой класс поддерживающий каждую из моделей.    

## Фреймворки
### Hugging Face    

1. Позволяет создать датасет	    
2. Позволяет опубликовать свой датасет	    
3. Инструменты для оценивания моделей на датасет.	    
4. Умеет считать метрики WER и CER

### vllm

Фреймворк для оптимизированного инференса и сервинга моделей    

Полезные ссылки о vllm ([ссылка](https://habr.com/ru/companies/mts_ai/articles/791594/) ускорение в 20 раз, сравнение инструментов сервинга LLM [ссылка](https://vc.ru/ai/1247008-sravnenie-proizvoditelnosti-servinga-llama-3-na-vllm-lmdeploy-mlc-llm-tensorrt-llm-i-tgi?ysclid=m3fjcweeog473826955)).
Как будто TensorRT + Triton inference server сразу) При этом поддерживаются не только nvidia GPU.
Из объективного анализа фреймворков для сервинга привлекательнее всего выглядит именно vllm =)

### Другие

1. [VL-CheckList](https://github.com/om-ai-lab/VL-CheckList) (2022)	
2. [UniBench](https://github.com/facebookresearch/unibench) [Paper](https://arxiv.org/abs/2408.04810) (2024)	
3. [HELM](https://github.com/stanford-crfm/helm) [Paper](https://arxiv.org/abs/2410.07112) (2023-2024)


## Общая стратегия

1. Запускаем модель хоть как то =)    
2. Затем стараемся на vllm

## Ресерч

Антон
- тестировать запуск [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)   

Семен
- Поискать свой бенчмарк для VLLM  
или
- Hugging Face datasets , vllm([ссылка](https://docs.vllm.ai/en/latest/) , [github](https://github.com/vllm-project/vllm))  
	1. Позволяет создать датасет	    
	2. Позволяет опубликовать свой датасет	    
	3. Инструменты для оценивания моделей на датасет.	    
	4. Умеет считать метрики WER и CER
или
- если не нашли то [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)    

Юлия
- поискать свой бенчмарк для VLLM для VQA	
- тестировать его    
- если не нашли то [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)    

Женя
- поискать свой бенчмарк для VLLM для VQA    
- тестировать его    
- если не нашли то [VLMEvalKit](https://github.com/open-compass/VLMEvalKit)    

  

Остальное:
- Велосипед от Антона 
[https://gitlab.com/document_vqa/vqa_dataset_bencmark](https://gitlab.com/document_vqa/vqa_dataset_bencmark)
