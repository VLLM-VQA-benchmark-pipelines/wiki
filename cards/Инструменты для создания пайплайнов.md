---
Author:
  - Овчинникова Юлия
  - Ширяев Антон
  - Изюмова Анастасия
tags:
  - pipeline
date: 2024-11-23
---
## Prefect (не подошел)

[Documentation](https://docs.prefect.io/v3/get-started/index), [Работа с Docker](https://prefect-python-sdk-docs.netlify.app/prefect_docker/containers/)
Язык: Python
Может работать с Docker
Есть графический интерфейс для отслеживания работы пайплайна
[Настройка параметров для Docker-контейнера в Prefect | DeepSeek](Prefect%20Настройка%20параметров%20для%20Docker-контейнера.md)


## Nextflow

[Documentation](https://nextflow.io/docs/latest/overview.html), [GitHub](https://github.com/nextflow-io/nextflow), [Basic pipeline](https://nextflow.io/example1.html)
Язык: Groovy
Может работать с Docker, Conda env
Можно писать на облаке [Gitpod](https://training.nextflow.io/envsetup/01_setup/#creating-a-gitpod-account)
Заточен больше для биоинформатиков, для них создано очень много готовых контейнеров
Можно настраивать параллельные процессы

Официальные обучалки с классным пошаговым разбором синтаксиса и возможностей 
[training.nextflow.io](https://training.nextflow.io/hello_nextflow/02_hello_world/),  [Github Training](https://github.com/nextflow-io/training)

[Настройка параметров для Docker-контейнера в Nextflow | DeepSeek](Nextflow%20Настройка%20параметров%20для%20Docker-контейнера.md)
[Tutorial Nextflow + Docker](https://github.com/serjisa/nextflow.tutorial)

## Snakemake

[Documentation](https://snakemake.readthedocs.io/en/stable/)
Язык: Python
Может работать с Docker, Conda env
Заточен больше для биоинформатиков
Может исполнять правила параллельно
По ощущениям менее понятный в работе с правилами O_O

## ClearML Pipelines

[Documentation](https://clear.ml/docs/latest/docs/pipelines/)
Заточен на ML/DL.
Выглядит как удобный инструмент с графическим интерфейсом пользователя.

#### Мнения:

Эксперт 1:
```
Только обрати внимание ClearML не очень удобно для кейса когда надо отдельный уникальный докер образ под каждый шаг. Придется создавать столько ClearML агентов, сколько у вас различных докер образов

Если один образ подойдет под все шаги, то норм
```

У нас как раз планируется что в одном шаге может быть использовано много разных докер образов.
## Appache AirFlow

[Documentation](https://airflow.apache.org/docs/)
Универсален и кажется может все, но сложно долго и нудно конфигурировать.

## Argo Workflows

[Documentation](https://argoproj.github.io/workflows/)

Argo Workflows — это оркестратор контейнеров для Kubernetes, который позволяет выполнять задачи в виде DAG. Argo Workflows поддерживает запуск задач в Docker-контейнерах и передачу параметров запуска.
#### Основные особенности:

- **Поддержка Kubernetes**: Argo Workflows работает на Kubernetes и позволяет запускать задачи в контейнерах.
- **Передача параметров**: Вы можете передавать параметры запуска контейнеров, такие как примонтированные папки и GPU.
- **Гибкость**: Argo Workflows предоставляет мощный DSL для создания сложных рабочих процессов.
    
#### Пример использования:

```
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: docker-workflow-
spec:
  entrypoint: docker-steps
  templates:
  - name: docker-steps
    steps:
    - - name: step1
        template: docker-task
        arguments:
          parameters: [{name: message, value: "Hello, World!"}]

  - name: docker-task
    inputs:
      parameters:
      - name: message
    container:
      image: your_docker_image
      command: [echo]
      args: ["{{inputs.parameters.message}}"]
      volumeMounts:
      - name: data
        mountPath: /container/path
      resources:
        limits:
          nvidia.com/gpu: 1
  volumes:
  - name: data
    hostPath:
      path: /host/path
```

## Kubeflow Pipelines

Kubeflow Pipelines — это платформа для оркестрации машинного обучения на Kubernetes. Она позволяет создавать и запускать рабочие процессы в виде DAG, где каждый шаг — это контейнер.

#### Основные особенности:

- **Поддержка Kubernetes**: Kubeflow Pipelines работает на Kubernetes и позволяет запускать задачи в контейнерах.
- **Передача параметров**: Вы можете передавать параметры запуска контейнеров, такие как примонтированные папки и GPU.
- **Гибкость**: Kubeflow Pipelines предоставляет мощный API для создания сложных рабочих процессов.

#### Пример использования:
```python
import kfp
from kfp import dsl

@dsl.pipeline(
  name='Docker Pipeline',
  description='A pipeline with Docker tasks.'
)
def docker_pipeline():
    dsl.ContainerOp(
        name='docker_task',
        image='your_docker_image',
        command=['echo'],
        arguments=['Hello, World!'],
        file_outputs={},
        pvolumes={
            '/host/path': dsl.PipelineVolume(pvc='data-volume')
        },
        resources={
            'limits': {
                'nvidia.com/gpu': '1'
            }
        }
    )

if __name__ == '__main__':
    kfp.compiler.Compiler().compile(docker_pipeline, 'docker_pipeline.yaml')
```

#### Мнения:

Эксперт 2:
```
У меня в отделе отдельный MLOps под это дело сидит.
Будут вопросы — смело пиши
```

Эксперт 1:
```
Хорошая штука, но кажется оверхед на развертывание и поддержание кубфлоу слишком большой
```