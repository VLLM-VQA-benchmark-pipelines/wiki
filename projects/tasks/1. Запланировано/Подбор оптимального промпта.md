---
Author:
  - Ширяев Антон
  - Изюмова Анастасия
Implementer: 
tags: 
start date: 
end date:
---
# Описание

Подобрать максимальный хороший промт под каждую модель на определенных данных

1. Ручной перебор
2. Использование автоматизированных инструментов для получения лучшего промпта для конкретной модели на конкретных данных.

Обсудили стратегии с Анастасией полуавтоматизированные способы подборки пропта:
1. https://www.promptingguide.ai/techniques/fewshot
2. https://lmarena.ai/
3. https://docs.confident-ai.com/docs/getting-started
4. https://textgrad.com/
5. https://medium.com/aiguys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10

Сообщение из тг [ссылка](https://t.me/white_tensor/500)
Если продолжаете заниматься ручным тюнингом промптов, то есть не плохая схема:

1. Нужен тестовый датасет (или отсматривать вручную, или размеченный)

2. Заходим на https://lmarena.ai/
— Генерировать будем через "Arena (battle)"
— Там есть и o1 новые, и в целом нет лимитов на генерацию

3. Формируем промпт для улучшения промпта:
— Берём текущие промпты и их скоры
— Рассказываем саму задачу и какие показатели ожидаем (иногда мы можем специально делать не общую точность максимальной, а recall, или только точные негативы)
— Просим проанализировать промпты которые уже есть и их скоры
— И просим написать новый промпт с учётом всего

4. Проверка сгенерированных промптов
— У нас будет 2 сгенерированных новых промпта от 2 рандомных моделей (на самом деле обычно там попадаются +- топовые модели, в том числе и новые как o1)
— Берём их и проверяем на нашем тестовом датасете
— Если какой-то из промптов понравился, то оставляем его себе и добавляем\заменяем в список промптов с метриками в улучшающий промпт
— Повторять можно бесконечно, со временем промпт по настоящему улучшается

Подобная техника в основном нужна, когда уже есть хорошие промпты и не особо получается их уже улучшить.

Из интересного:
▫️ Далеко не всегда лучшие промпты придумывает лучшая модель
▫️ Часто лучший промпт придумывает модель из того же семейства (та же самая, или с большим кол-вом параметров). Например, для gemma2-9b-it это gemma2-27b-it, для qwen2.5-32b-instruct это оказалась API версия qwen-plus

Так же напоминаю про textgrad (https://github.com/zou-group/textgradhttps://github.com/zou-group/textgrad), который тоже можно использовать для автоматического улучшения промптов.
